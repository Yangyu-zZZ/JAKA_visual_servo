import time
import sys
import traceback
import threading
import queue
from dataclasses import dataclass, field
from enum import Enum
from typing import Optional, Tuple, List
from pathlib import Path

# ç¬¬ä¸‰æ–¹ä¾èµ–
try:
    import pyrealsense2 as rs
    import numpy as np
    import cv2
    import serial
    import msvcrt
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦æ¨¡å—: {e}")
    print("è¯·å®‰è£…: pip install pyrealsense2 numpy opencv-python pyserial")
    sys.exit(1)

# JAKAæœºå™¨äººæ¨¡å—
try:
    import __common
    from jaka_robot import JAKARobotController
    from jaka_robot.constants import RobotConstants
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥ jaka_robot: {e}")
    sys.exit(1)


# ============================================================================
# é…ç½®ç®¡ç†
# ============================================================================

@dataclass
class RobotConfig:
    """æœºå™¨äººé…ç½®"""
    ip: str = "10.5.5.100"
    home_joint_deg: List[float] = field(default_factory=lambda: [0, 0, 90, 0, 90, -90])
    # plane_z: float = 250.0  # å·¥ä½œå¹³é¢é«˜åº¦(mm)
    
    @property
    def home_joint_rad(self) -> List[float]:
        return [np.deg2rad(j) for j in self.home_joint_deg]


# @dataclass
# class GripperConfig:
#     """å¤¹çˆªé…ç½®"""
#     port: str = "COM6"
#     baudrate: int = 115200
#     timeout: float = 1.0


@dataclass
class CameraConfig:
    """ç›¸æœºé…ç½®"""
    width: int = 640
    height: int = 480
    fps: int = 60
    format: str = "bgr8"


@dataclass
class ControlConfig:
    """æ§åˆ¶å‚æ•°é…ç½®"""
    # åƒç´ åˆ°æ¯«ç±³çš„è½¬æ¢å¢ç›Š
    gain_x_per_pixel: float = 0.05
    gain_y_per_pixel: float = 0.05
    
    # PIDå‚æ•°
    use_pid: bool = True
    pid_x_kp: float = 0.05
    pid_x_ki: float = 0.0
    pid_x_kd: float = 0.01
    pid_y_kp: float = 0.05
    pid_y_ki: float = 0.0
    pid_y_kd: float = 0.01
    pid_integral_limit: float = 500.0
    
    # é™åˆ¶å‚æ•°
    pixel_dead_band: float = 3.0
    stable_pixel_band: float = 2.0
    stable_required_frames: int = 5
    max_step_mm: float = 20.0
    min_cmd_mm: float = 0.2
    
    # å¹³æ»‘å‚æ•°
    use_ema_smooth: bool = True
    ema_alpha: float = 0.3
    
    # ä¼ºæœå‚æ•°
    use_servo_streaming: bool = True
    servo_interval: float = 0.0167  # ~60Hz
    
    # æ»¤æ³¢å™¨é…ç½®
    use_servo_filter: bool = True
    servo_filter_type: str = 'CARTESIAN_NLF'
    cart_max_vp: float = 180.0
    cart_max_ap: float = 800.0
    cart_max_jp: float = 4000.0
    cart_max_vr: float = 60.0
    cart_max_ar: float = 300.0
    cart_max_jr: float = 1500.0


@dataclass
class VisionConfig:
    """è§†è§‰æ£€æµ‹é…ç½®"""
    # HSVçº¢è‰²é˜ˆå€¼èŒƒå›´
    red_lower_1: Tuple[int, int, int] = (0, 70, 50)
    red_upper_1: Tuple[int, int, int] = (10, 255, 255)
    red_lower_2: Tuple[int, int, int] = (170, 70, 50)
    red_upper_2: Tuple[int, int, int] = (180, 255, 255)
    
    # å½¢æ€å­¦æ“ä½œ
    morph_kernel_size: int = 5
    min_contour_area: float = 200.0
    approx_epsilon: float = 0.02
    
    # è°ƒè¯•
    debug_save_interval: int = 0  # 0=ä¸ä¿å­˜


# ============================================================================
# è¿è¡ŒçŠ¶æ€
# ============================================================================

class SystemState(Enum):
    """ç³»ç»Ÿè¿è¡ŒçŠ¶æ€"""
    IDLE = "idle"
    CAPTURING = "capturing"
    TRACKING = "tracking"
    PAUSED = "paused"
    ERROR = "error"


# ============================================================================
# PIDæ§åˆ¶å™¨
# ============================================================================

class PIDController:
    """PIDæ§åˆ¶å™¨å®ç°"""
    
    def __init__(self, kp: float, ki: float, kd: float, 
                 output_limit: float, integral_limit: float):
        self.kp = float(kp)
        self.ki = float(ki)
        self.kd = float(kd)
        self.output_limit = float(output_limit)
        self.integral_limit = float(integral_limit)
        
        self.integral = 0.0
        self.prev_error: Optional[float] = None
    
    def reset(self) -> None:
        """é‡ç½®PIDçŠ¶æ€"""
        self.integral = 0.0
        self.prev_error = None
    
    def update(self, error: float, dt: float) -> float:
        """
        è®¡ç®—PIDè¾“å‡º
        
        Args:
            error: å½“å‰è¯¯å·®
            dt: æ—¶é—´æ­¥é•¿(ç§’)
            
        Returns:
            æ§åˆ¶è¾“å‡ºå€¼
        """
        dt = max(dt, 1e-3)  # é˜²æ­¢é™¤é›¶
        
        # ç§¯åˆ†é¡¹
        self.integral += error * dt
        self.integral = np.clip(self.integral, -self.integral_limit, self.integral_limit)
        
        # å¾®åˆ†é¡¹
        if self.prev_error is None:
            derivative = 0.0
        else:
            derivative = (error - self.prev_error) / dt
        self.prev_error = error
        
        # PIDè¾“å‡º
        output = self.kp * error + self.ki * self.integral + self.kd * derivative
        output = np.clip(output, -self.output_limit, self.output_limit)
        
        return float(output)


# ============================================================================
# ç¡¬ä»¶æ¥å£å±‚
# ============================================================================

# class Gripper:
#     """å¤¹çˆªæ§åˆ¶å™¨"""
    
#     # å‘½ä»¤å­—èŠ‚åºåˆ—
#     CMD_OPEN = bytes([0x7b, 0x01, 0x02, 0x00, 0x20, 0x49, 0x20, 0x00, 0xc8, 0xF9, 0x7d])
#     CMD_CLOSE = bytes([0x7b, 0x01, 0x02, 0x01, 0x20, 0x49, 0x20, 0x00, 0xc8, 0xF8, 0x7d])
    
#     def __init__(self, config: GripperConfig):
#         self.config = config
#         self.serial: Optional[serial.Serial] = None
    
#     def initialize(self) -> bool:
#         """åˆå§‹åŒ–ä¸²å£è¿æ¥"""
#         try:
#             self.serial = serial.Serial(
#                 port=self.config.port,
#                 baudrate=self.config.baudrate,
#                 timeout=self.config.timeout
#             )
#             if not self.serial.is_open:
#                 print(f"âŒ ä¸²å£ {self.config.port} æ‰“å¼€å¤±è´¥")
#                 return False
#             print(f"âœ… å¤¹çˆªä¸²å£ {self.config.port} å·²è¿æ¥")
#             return True
#         except Exception as e:
#             print(f"âŒ å¤¹çˆªåˆå§‹åŒ–å¤±è´¥: {e}")
#             return False
    
#     def open(self) -> bool:
#         """æ‰“å¼€å¤¹çˆª"""
#         if self.serial and self.serial.is_open:
#             try:
#                 self.serial.write(self.CMD_OPEN)
#                 print("ğŸ”“ å¤¹çˆªæ‰“å¼€")
#                 return True
#             except Exception as e:
#                 print(f"âŒ å¤¹çˆªæ‰“å¼€å¤±è´¥: {e}")
#                 return False
#         return False
    
#     def close(self) -> bool:
#         """é—­åˆå¤¹çˆª"""
#         if self.serial and self.serial.is_open:
#             try:
#                 self.serial.write(self.CMD_CLOSE)
#                 print("ğŸ”’ å¤¹çˆªé—­åˆ")
#                 return True
#             except Exception as e:
#                 print(f"âŒ å¤¹çˆªé—­åˆå¤±è´¥: {e}")
#                 return False
#         return False
    
#     def cleanup(self) -> None:
#         """æ¸…ç†èµ„æº"""
#         if self.serial and self.serial.is_open:
#             self.serial.close()
#             print("âœ… å¤¹çˆªä¸²å£å·²å…³é—­")


class RealSenseCamera:
    """RealSenseç›¸æœºæ¥å£"""
    
    def __init__(self, config: CameraConfig):
        self.config = config
        self.pipeline: Optional[rs.pipeline] = None
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–ç›¸æœº"""
        try:
            self.pipeline = rs.pipeline()
            config = rs.config()
            config.enable_stream(
                rs.stream.color,
                self.config.width,
                self.config.height,
                getattr(rs.format, self.config.format),
                self.config.fps
            )
            self.pipeline.start(config)
            print("âœ… RealSenseç›¸æœºåˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ ç›¸æœºåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def get_frame(self) -> Optional[np.ndarray]:
        """è·å–å½©è‰²å›¾åƒå¸§"""
        if not self.pipeline:
            return None
        
        try:
            frames = self.pipeline.wait_for_frames(timeout_ms=1000)
            color_frame = frames.get_color_frame()
            if not color_frame:
                return None
            return np.asanyarray(color_frame.get_data())
        except Exception as e:
            print(f"âš ï¸ è·å–å›¾åƒå¸§å¤±è´¥: {e}")
            return None
    
    def stop(self) -> None:
        """åœæ­¢ç›¸æœº"""
        if self.pipeline:
            self.pipeline.stop()
            print("âœ… ç›¸æœºå·²åœæ­¢")


# ============================================================================
# è§†è§‰æ£€æµ‹æ¨¡å—
# ============================================================================

@dataclass
class DetectionResult:
    """æ£€æµ‹ç»“æœ"""
    corners: np.ndarray  # 4x2
    centroid: Tuple[int, int]
    debug_image: np.ndarray


class RedSquareDetector:
    """çº¢è‰²æ­£æ–¹å½¢æ£€æµ‹å™¨"""
    
    def __init__(self, config: VisionConfig):
        self.config = config
        self._morph_kernel = np.ones(
            (config.morph_kernel_size, config.morph_kernel_size),
            np.uint8
        )
    
    def detect(self, image: np.ndarray) -> Optional[DetectionResult]:
        """
        æ£€æµ‹çº¢è‰²æ­£æ–¹å½¢
        
        Args:
            image: BGRæ ¼å¼å›¾åƒ
            
        Returns:
            æ£€æµ‹ç»“æœæˆ–None
        """
        debug_img = image.copy()
        
        # HSVé¢œè‰²ç©ºé—´è½¬æ¢
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # çº¢è‰²åŒé˜ˆå€¼æ©ç 
        mask1 = cv2.inRange(hsv, self.config.red_lower_1, self.config.red_upper_1)
        mask2 = cv2.inRange(hsv, self.config.red_lower_2, self.config.red_upper_2)
        mask = cv2.bitwise_or(mask1, mask2)
        
        # å½¢æ€å­¦é™å™ª
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, self._morph_kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, self._morph_kernel)
        
        # è½®å»“æ£€æµ‹
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return None
        
        # é€‰æ‹©æœ€å¤§è½®å»“
        largest_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)
        
        if area < self.config.min_contour_area:
            return None
        
        # å¤šè¾¹å½¢é€¼è¿‘
        perimeter = cv2.arcLength(largest_contour, True)
        approx = cv2.approxPolyDP(
            largest_contour,
            self.config.approx_epsilon * perimeter,
            True
        )
        
        # è·å–è§’ç‚¹
        if len(approx) == 4:
            corners = approx.reshape(4, 2)
        else:
            # å›é€€åˆ°å¤–æ¥çŸ©å½¢
            x, y, w, h = cv2.boundingRect(largest_contour)
            corners = np.array([
                [x, y], [x + w, y],
                [x + w, y + h], [x, y + h]
            ])
        
        # è§’ç‚¹æ’åº(å·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹)
        corners = self._order_corners(corners)
        
        # è®¡ç®—è´¨å¿ƒ
        moments = cv2.moments(largest_contour)
        if moments["m00"] != 0:
            cx = int(moments["m10"] / moments["m00"])
            cy = int(moments["m01"] / moments["m00"])
        else:
            cx, cy = corners.mean(axis=0).astype(int)
        centroid = (cx, cy)
        
        # ç»˜åˆ¶è°ƒè¯•ä¿¡æ¯
        self._draw_debug_info(debug_img, corners, centroid)
        
        return DetectionResult(corners, centroid, debug_img)
    
    @staticmethod
    def _order_corners(corners: np.ndarray) -> np.ndarray:
        """æŒ‰å·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹é¡ºåºæ’åˆ—è§’ç‚¹"""
        sorted_by_y = corners[np.argsort(corners[:, 1])]
        top_two = sorted_by_y[:2]
        bottom_two = sorted_by_y[2:]
        
        top_sorted = top_two[np.argsort(top_two[:, 0])]
        bottom_sorted = bottom_two[np.argsort(bottom_two[:, 0])]
        
        return np.vstack([top_sorted, bottom_sorted[::-1]])
    
    @staticmethod
    def _draw_debug_info(image: np.ndarray, corners: np.ndarray,
                        centroid: Tuple[int, int]) -> None:
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶è°ƒè¯•ä¿¡æ¯"""
        # ç»˜åˆ¶è§’ç‚¹
        for i, (x, y) in enumerate(corners):
            cv2.circle(image, (int(x), int(y)), 5, (0, 255, 0), -1)
            cv2.putText(image, str(i), (int(x) + 5, int(y) - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        # ç»˜åˆ¶è´¨å¿ƒ
        cv2.circle(image, centroid, 6, (255, 0, 0), -1)
        cv2.putText(image, f"C({centroid[0]},{centroid[1]})",
                   (centroid[0] + 8, centroid[1] + 8),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)


class FeatureTracker:
    """ç‰¹å¾è¿½è¸ªå™¨"""
    
    def __init__(self, detector: RedSquareDetector, vision_config: VisionConfig):
        self.detector = detector
        self.config = vision_config
        
        self.reference_centroid: Optional[Tuple[int, int]] = None
        self.reference_corners: Optional[np.ndarray] = None
        self.is_initialized = False
        self._frame_counter = 0
    
    def capture_reference(self, image: np.ndarray) -> bool:
        """æ•è·å‚è€ƒå¸§"""
        result = self.detector.detect(image)
        if result is None:
            print("âŒ æœªæ£€æµ‹åˆ°çº¢è‰²æ–¹å—")
            return False
        
        self.reference_centroid = result.centroid
        self.reference_corners = result.corners
        self.is_initialized = True
        
        # ä¿å­˜å‚è€ƒå›¾åƒ
        cv2.imwrite("reference.jpg", result.debug_image)
        print(f"âœ… å‚è€ƒå¸§å·²æ•è·: è´¨å¿ƒ={result.centroid}")
        
        return True
    
    def compute_offset(self, image: np.ndarray) -> Optional[Tuple[int, int, np.ndarray]]:
        """
        è®¡ç®—åƒç´ åç§»
        
        Returns:
            (dx, dy, debug_image) æˆ– None
        """
        if not self.is_initialized:
            return None
        
        result = self.detector.detect(image)
        if result is None:
            return None
        
        # è®¡ç®—åç§»
        dx = result.centroid[0] - self.reference_centroid[0]
        dy = result.centroid[1] - self.reference_centroid[1]
        
        # ç»˜åˆ¶å‚è€ƒç‚¹å’Œåç§»å‘é‡
        debug_img = result.debug_image
        ref_pos = self.reference_centroid
        cur_pos = result.centroid
        
        cv2.drawMarker(debug_img, ref_pos, (0, 255, 255),
                      cv2.MARKER_CROSS, 12, 2)
        cv2.arrowedLine(debug_img, ref_pos, cur_pos, (0, 255, 255), 2, tipLength=0.25)
        cv2.putText(debug_img, f"Offset: dx={dx}px dy={dy}px",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # å®šæœŸä¿å­˜è°ƒè¯•å›¾åƒ
        if self.config.debug_save_interval > 0:
            self._frame_counter += 1
            if self._frame_counter % self.config.debug_save_interval == 0:
                cv2.imwrite("tracking_debug.jpg", debug_img)
        
        return dx, dy, debug_img


# ============================================================================
# è¿åŠ¨æ§åˆ¶æ¨¡å—
# ============================================================================

class MotionController:
    """æœºå™¨äººè¿åŠ¨æ§åˆ¶å™¨"""
    
    def __init__(self, robot: JAKARobotController, config: ControlConfig):
        self.robot = robot
        self.config = config
        
        # PIDæ§åˆ¶å™¨
        self.pid_x = PIDController(
            config.pid_x_kp, config.pid_x_ki, config.pid_x_kd,
            config.max_step_mm, config.pid_integral_limit
        )
        self.pid_y = PIDController(
            config.pid_y_kp, config.pid_y_ki, config.pid_y_kd,
            config.max_step_mm, config.pid_integral_limit
        )
        
        # çŠ¶æ€å˜é‡
        self.last_timestamp: Optional[float] = None
        self.ema_dx = 0.0
        self.ema_dy = 0.0
        self.stable_counter = 0
        
        # å¼‚æ­¥è¿åŠ¨é˜Ÿåˆ—(éæµå¼æ¨¡å¼)
        self._motion_queue: queue.Queue = queue.Queue(maxsize=1)
        self._motion_stop = threading.Event()
        self._motion_thread: Optional[threading.Thread] = None
    
    def reset(self) -> None:
        """é‡ç½®æ§åˆ¶å™¨çŠ¶æ€"""
        self.pid_x.reset()
        self.pid_y.reset()
        self.last_timestamp = time.time()
        self.ema_dx = 0.0
        self.ema_dy = 0.0
        self.stable_counter = 0
    
    def compute_control_command(self, dx: float, dy: float) -> Tuple[float, float]:
        """
        è®¡ç®—æ§åˆ¶å‘½ä»¤
        
        Args:
            dx, dy: åƒç´ åç§»(å·¦è´Ÿå³æ­£, ä¸Šè´Ÿä¸‹æ­£)
            
        Returns:
            (delta_x_mm, delta_y_mm): æœºå™¨äººåæ ‡ç³»ä¸‹çš„å¢é‡(mm)
        """
        # æŒ‡æ•°å¹³æ»‘
        if self.config.use_ema_smooth:
            self.ema_dx = self.config.ema_alpha * dx + (1 - self.config.ema_alpha) * self.ema_dx
            self.ema_dy = self.config.ema_alpha * dy + (1 - self.config.ema_alpha) * self.ema_dy
            smooth_dx, smooth_dy = self.ema_dx, self.ema_dy
        else:
            smooth_dx, smooth_dy = dx, dy
        
        # æ­»åŒºåˆ¤æ–­
        if abs(smooth_dx) < self.config.pixel_dead_band and \
           abs(smooth_dy) < self.config.pixel_dead_band:
            # ç¨³å®šæ€§è®¡æ•°
            if abs(smooth_dx) < self.config.stable_pixel_band and \
               abs(smooth_dy) < self.config.stable_pixel_band:
                self.stable_counter = min(self.stable_counter + 1, 1000)
            else:
                self.stable_counter = 0
            
            # ç¨³å®šæ—¶é‡ç½®PIDç§¯åˆ†
            if self.config.use_pid and \
               self.stable_counter >= self.config.stable_required_frames:
                self.pid_x.reset()
                self.pid_y.reset()
            
            return 0.0, 0.0
        
        # è®¡ç®—æ—¶é—´æ­¥é•¿
        now = time.time()
        if self.last_timestamp is None:
            dt = self.config.servo_interval
        else:
            dt = now - self.last_timestamp
        self.last_timestamp = now
        
        # è®¡ç®—æ§åˆ¶é‡
        # æ˜ å°„è§„åˆ™: å·¦ç§»(dx<0) â†’ yè´Ÿ; ä¸‹ç§»(dy>0) â†’ xæ­£
        if self.config.use_pid:
            cmd_x = self.pid_x.update(smooth_dy, dt)
            cmd_y = self.pid_y.update(smooth_dx, dt)
        else:
            cmd_x = self.config.gain_x_per_pixel * smooth_dy
            cmd_y = self.config.gain_y_per_pixel * smooth_dx
        
        # é™å¹…
        cmd_x = np.clip(cmd_x, -self.config.max_step_mm, self.config.max_step_mm)
        cmd_y = np.clip(cmd_y, -self.config.max_step_mm, self.config.max_step_mm)
        
        # æœ€å°é˜ˆå€¼
        if abs(cmd_x) < self.config.min_cmd_mm:
            cmd_x = 0.0
        if abs(cmd_y) < self.config.min_cmd_mm:
            cmd_y = 0.0
        
        return cmd_x, cmd_y
    
    def execute_move(self, delta_x: float, delta_y: float) -> bool:
        """
        æ‰§è¡Œè¿åŠ¨å‘½ä»¤
        
        Args:
            delta_x, delta_y: æœºå™¨äººåæ ‡ç³»å¢é‡(mm)
        """
        if delta_x == 0.0 and delta_y == 0.0:
            return True
        
        if self.config.use_servo_streaming:
            # æµå¼ä¼ºæœæ¨¡å¼
            try:
                increment = [delta_x, delta_y, 0.0, 0.0, 0.0, 0.0]
                self.robot.motion.servo_p(increment, RobotConstants.INCR)
                return True
            except Exception as e:
                print(f"âŒ servo_pæ‰§è¡Œå¤±è´¥: {e}")
                return False
        else:
            # å¼‚æ­¥é˜Ÿåˆ—æ¨¡å¼
            self._submit_to_queue(delta_x, delta_y)
            return True
    
    def _submit_to_queue(self, delta_x: float, delta_y: float) -> None:
        """æäº¤è¿åŠ¨åˆ°å¼‚æ­¥é˜Ÿåˆ—"""
        try:
            if self._motion_queue.full():
                self._motion_queue.get_nowait()
            self._motion_queue.put_nowait((delta_x, delta_y))
        except Exception:
            pass
    
    def start_async_motion_worker(self) -> None:
        """å¯åŠ¨å¼‚æ­¥è¿åŠ¨çº¿ç¨‹"""
        if not self.config.use_servo_streaming:
            if self._motion_thread is None or not self._motion_thread.is_alive():
                self._motion_stop.clear()
                self._motion_thread = threading.Thread(
                    target=self._motion_worker,
                    name="motion-worker",
                    daemon=True
                )
                self._motion_thread.start()
    
    def _motion_worker(self) -> None:
        """è¿åŠ¨çº¿ç¨‹å·¥ä½œå‡½æ•°"""
        while not self._motion_stop.is_set():
            try:
                cmd = self._motion_queue.get(timeout=0.05)
            except queue.Empty:
                continue
            
            # è·å–æœ€æ–°å‘½ä»¤
            try:
                while True:
                    cmd = self._motion_queue.get_nowait()
            except queue.Empty:
                pass
            
            delta_x, delta_y = cmd
            self._execute_plane_move(delta_x, delta_y)
    
    def _execute_plane_move(self, delta_x: float, delta_y: float) -> bool:
        """æ‰§è¡Œå¹³é¢è¿åŠ¨"""
        try:
            # è·å–å½“å‰TCPä½å§¿
            ret = self.robot.status.get_tcp_position()
            if ret[0] != 0:
                return False
            
            # è®¡ç®—ç›®æ ‡ä½å§¿
            current_pose = ret[1]
            target_pose = current_pose.copy()
            target_pose[0] += delta_x
            target_pose[1] += delta_y
            # ä¿æŒZé«˜åº¦
            # target_pose[2] = self.config.plane_z (å¦‚éœ€è¦)
            
            # é€†è§£
            ik_result = self.robot.coordinate.kine_inverse(
                self.robot.status.get_joint_position()[1],
                target_pose
            )
            if ik_result[0] != 0:
                return False
            
            # æ‰§è¡Œè¿åŠ¨
            move_result = self.robot.motion.joint_move(
                ik_result[1],
                RobotConstants.ABS,
                True,
                0.6
            )
            return move_result[0] == 0
            
        except Exception as e:
            print(f"âŒ å¹³é¢è¿åŠ¨æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    def stop_async_worker(self) -> None:
        """åœæ­¢å¼‚æ­¥è¿åŠ¨çº¿ç¨‹"""
        if self._motion_thread is not None:
            self._motion_stop.set()
            self._motion_thread.join(timeout=1.0)


# ============================================================================
# ä¸»ç³»ç»Ÿ
# ============================================================================

class VisualServoSystem:
    """è§†è§‰ä¼ºæœç³»ç»Ÿä¸»æ§"""
    
    def __init__(self,
                 robot_config: RobotConfig,
                #  gripper_config: GripperConfig,
                 camera_config: CameraConfig,
                 control_config: ControlConfig,
                 vision_config: VisionConfig):
        
        # é…ç½®
        self.robot_cfg = robot_config
        self.control_cfg = control_config
        
        # ç¡¬ä»¶
        self.robot: Optional[JAKARobotController] = None
        # self.gripper = Gripper(gripper_config)
        self.camera = RealSenseCamera(camera_config)
        
        # è§†è§‰ä¸æ§åˆ¶
        self.detector = RedSquareDetector(vision_config)
        self.tracker = FeatureTracker(self.detector, vision_config)
        self.motion_controller: Optional[MotionController] = None
        
        # çŠ¶æ€
        self.state = SystemState.IDLE
        self.last_offset = (0, 0)
        self.last_command = (0.0, 0.0)
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        print("\n" + "="*50)
        print("è§†è§‰ä¼ºæœç³»ç»Ÿåˆå§‹åŒ–")
        print("="*50 + "\n")
        
        # æœºå™¨äºº
        print("ğŸ¤– åˆå§‹åŒ–æœºå™¨äºº...")
        self.robot = JAKARobotController(self.robot_cfg.ip)
        if not self.robot.utils.initialize_robot():
            print("âŒ æœºå™¨äººåˆå§‹åŒ–å¤±è´¥")
            return False
        
        # å›åˆ°åˆå§‹ä½ç½®
        ret = self.robot.motion.joint_move(
            self.robot_cfg.home_joint_rad,
            RobotConstants.ABS,
            True,
            0.2
        )
        if ret[0] != 0:
            print(f"âŒ å›åˆ°åˆå§‹ä½ç½®å¤±è´¥: {ret[0]}")
            return False
        print("âœ… æœºå™¨äººå°±ç»ª")
        
        # å¤¹çˆª
        # print("\nğŸ¤ åˆå§‹åŒ–å¤¹çˆª...")
        # if not self.gripper.initialize():
        #     return False
        # self.gripper.open()
        
        # ç›¸æœº
        print("\nğŸ“· åˆå§‹åŒ–ç›¸æœº...")
        if not self.camera.initialize():
            return False
        
        # è¿åŠ¨æ§åˆ¶å™¨
        self.motion_controller = MotionController(self.robot, self.control_cfg)
        self.motion_controller.start_async_motion_worker()
        
        # é…ç½®ä¼ºæœæ»¤æ³¢å™¨
        if self.control_cfg.use_servo_streaming and self.control_cfg.use_servo_filter:
            self._configure_servo_filter()
        
        print("\n" + "="*50)
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print("="*50 + "\n")
        return True
    
    def _configure_servo_filter(self) -> None:
        """é…ç½®ä¼ºæœæ»¤æ³¢å™¨"""
        filter_type = self.control_cfg.servo_filter_type
        
        try:
            if filter_type == 'NONE':
                ret = self.robot.motion.servo_move_use_none_filter()
            elif filter_type == 'CARTESIAN_NLF':
                ret = self.robot.motion.servo_move_use_carte_NLF(
                    self.control_cfg.cart_max_vp,
                    self.control_cfg.cart_max_ap,
                    self.control_cfg.cart_max_jp,
                    self.control_cfg.cart_max_vr,
                    self.control_cfg.cart_max_ar,
                    self.control_cfg.cart_max_jr
                )
            else:
                print(f"âš ï¸ æœªçŸ¥æ»¤æ³¢å™¨ç±»å‹: {filter_type}")
                return
            
            if ret[0] == 0:
                print(f"âœ… ä¼ºæœæ»¤æ³¢å™¨å·²é…ç½®: {filter_type}")
            else:
                print(f"âš ï¸ æ»¤æ³¢å™¨é…ç½®å¤±è´¥: {ret}")
                
        except Exception as e:
            print(f"âš ï¸ æ»¤æ³¢å™¨é…ç½®å¼‚å¸¸: {e}")
    
    def run(self) -> None:
        """ä¸»è¿è¡Œå¾ªç¯"""
        if not self.initialize():
            print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return
        
        self._print_usage()
        
        try:
            cv2.namedWindow('Visual Servo', cv2.WINDOW_NORMAL)
            
            while True:
                # è·å–å›¾åƒå¸§
                frame = self.camera.get_frame()
                if frame is None:
                    time.sleep(0.05)
                    continue
                
                # å¤„ç†å½“å‰å¸§
                display_frame = self._process_frame(frame)
                
                # æ˜¾ç¤º
                cv2.imshow('Visual Servo', display_frame)
                cv2.waitKey(1)
                
                # é”®ç›˜è¾“å…¥
                if msvcrt.kbhit():
                    key = msvcrt.getch().decode('utf-8', errors='ignore')
                    if not self._handle_key(key):
                        break
                
                # è¿è¡Œæ—¶å»¶æ—¶
                if self.state != SystemState.TRACKING:
                    time.sleep(0.05)
                else:
                    time.sleep(self.control_cfg.servo_interval)
                    
        except KeyboardInterrupt:
            print("\nâš ï¸ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·")
        except Exception as e:
            print(f"âŒ è¿è¡Œæ—¶é”™è¯¯: {e}")
            traceback.print_exc()
        finally:
            self.cleanup()
    
    def _process_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        å¤„ç†å•å¸§å›¾åƒ
        
        Returns:
            ç”¨äºæ˜¾ç¤ºçš„å›¾åƒ
        """
        # æ£€æµ‹
        result = self.detector.detect(frame)
        display = result.debug_image if result else frame.copy()
        
        # å¦‚æœå·²åˆå§‹åŒ–è¿½è¸ª
        if self.tracker.is_initialized:
            offset_result = self.tracker.compute_offset(frame)
            if offset_result:
                dx, dy, display = offset_result
                self.last_offset = (dx, dy)
                
                # å¦‚æœå¤„äºè¿½è¸ªçŠ¶æ€ï¼Œæ‰§è¡Œä¼ºæœ
                if self.state == SystemState.TRACKING:
                    self._execute_servo_step(dx, dy)
        
        # å åŠ UIä¿¡æ¯
        self._draw_ui_overlay(display)
        
        return display
    
    def _execute_servo_step(self, dx: int, dy: int) -> None:
        """æ‰§è¡Œå•æ­¥ä¼ºæœ"""
        if self.motion_controller is None:
            return
        
        # è®¡ç®—æ§åˆ¶å‘½ä»¤
        cmd_x, cmd_y = self.motion_controller.compute_control_command(dx, dy)
        self.last_command = (cmd_x, cmd_y)
        
        # æ‰§è¡Œè¿åŠ¨
        if cmd_x != 0.0 or cmd_y != 0.0:
            self.motion_controller.execute_move(cmd_x, cmd_y)
    
    def _draw_ui_overlay(self, image: np.ndarray) -> None:
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶UIä¿¡æ¯"""
        h, w = image.shape[:2]
        y = 60
        scale = 0.6
        thickness = 2
        color_status = (0, 255, 0) if self.state == SystemState.TRACKING else (0, 165, 255)
        
        # çŠ¶æ€
        cv2.putText(image, f"State: {self.state.value.upper()}", 
                   (10, y), cv2.FONT_HERSHEY_SIMPLEX, scale, color_status, thickness)
        y += 25
        
        # åç§»
        if self.tracker.is_initialized:
            dx, dy = self.last_offset
            cv2.putText(image, f"Offset: dx={dx:+4d}px  dy={dy:+4d}px", 
                       (10, y), cv2.FONT_HERSHEY_SIMPLEX, scale, (255, 255, 0), thickness)
            y += 25
            
            # å‘½ä»¤
            cmd_x, cmd_y = self.last_command
            cv2.putText(image, f"Command: X={cmd_x:+6.2f}mm  Y={cmd_y:+6.2f}mm", 
                       (10, y), cv2.FONT_HERSHEY_SIMPLEX, scale, (255, 255, 0), thickness)
            y += 25
        
        # æ§åˆ¶å‚æ•°
        if self.control_cfg.use_pid:
            cv2.putText(image, 
                       f"PID: Kp={self.control_cfg.pid_x_kp:.3f} Ki={self.control_cfg.pid_x_ki:.3f} Kd={self.control_cfg.pid_x_kd:.3f}", 
                       (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 255), 1)
        else:
            cv2.putText(image, 
                       f"Gain: X={self.control_cfg.gain_x_per_pixel:.3f} Y={self.control_cfg.gain_y_per_pixel:.3f}", 
                       (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        y += 22
        
        # æ¨¡å¼
        mode = "Servo Stream" if self.control_cfg.use_servo_streaming else "Async Queue"
        cv2.putText(image, f"Mode: {mode}", 
                   (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (180, 255, 180), 1)
    
    def _handle_key(self, key: str) -> bool:
        """
        å¤„ç†é”®ç›˜è¾“å…¥
        
        Returns:
            Trueç»§ç»­è¿è¡Œï¼ŒFalseé€€å‡º
        """
        if key == 'c':
            self._handle_capture()
        elif key == 's':
            self._handle_start_stop()
        elif key == 'p':
            self._handle_pause()
        elif key == 'i':
            self._handle_return_home()
        elif key == 'q':
            print("ğŸ‘‹ é€€å‡ºç¨‹åº...")
            return False
        
        return True
    
    def _handle_capture(self) -> None:
        """å¤„ç†æ•è·å‘½ä»¤"""
        print("\nğŸ“¸ æ•è·å‚è€ƒå¸§...")
        self.state = SystemState.CAPTURING
        
        frame = self.camera.get_frame()
        if frame is not None and self.tracker.capture_reference(frame):
            self.state = SystemState.IDLE
        else:
            print("âŒ æ•è·å¤±è´¥")
            self.state = SystemState.ERROR
    
    def _handle_start_stop(self) -> None:
        """å¤„ç†å¯åŠ¨/åœæ­¢å‘½ä»¤"""
        if not self.tracker.is_initialized:
            print("âš ï¸ è¯·å…ˆæŒ‰ 'c' æ•è·å‚è€ƒå¸§")
            return
        
        if self.state == SystemState.TRACKING:
            # åœæ­¢è¿½è¸ª
            self.state = SystemState.IDLE
            print("â¸ï¸ è¿½è¸ªå·²åœæ­¢")
            
            if self.control_cfg.use_servo_streaming:
                try:
                    self.robot.motion.servo_move_enable(False)
                    print("âœ… ä¼ºæœæ¨¡å¼å·²å…³é—­")
                except Exception as e:
                    print(f"âš ï¸ å…³é—­ä¼ºæœå¤±è´¥: {e}")
        else:
            # å¯åŠ¨è¿½è¸ª
            self.state = SystemState.TRACKING
            print("â–¶ï¸ è¿½è¸ªå·²å¯åŠ¨")
            
            # é‡ç½®æ§åˆ¶å™¨
            if self.motion_controller:
                self.motion_controller.reset()
            
            # å¯ç”¨ä¼ºæœæ¨¡å¼
            if self.control_cfg.use_servo_streaming:
                try:
                    ret = self.robot.motion.servo_move_enable(True)
                    if ret[0] == 0:
                        print("âœ… ä¼ºæœæ¨¡å¼å·²å¯ç”¨")
                    else:
                        print(f"âš ï¸ ä¼ºæœå¯ç”¨å¤±è´¥: {ret}")
                except Exception as e:
                    print(f"âš ï¸ ä¼ºæœå¯ç”¨å¼‚å¸¸: {e}")
    
    def _handle_pause(self) -> None:
        """å¤„ç†æš‚åœå‘½ä»¤"""
        if self.state == SystemState.TRACKING:
            self.state = SystemState.PAUSED
            print("â¸ï¸ ç³»ç»Ÿå·²æš‚åœ")
            
            if self.control_cfg.use_servo_streaming:
                try:
                    self.robot.motion.servo_move_enable(False)
                except Exception:
                    pass
        else:
            print("â„¹ï¸ ç³»ç»Ÿæœªåœ¨è¿è¡Œ")
    
    def _handle_return_home(self) -> None:
        """å¤„ç†å›åˆå§‹ä½ç½®å‘½ä»¤"""
        print("\nğŸ  è¿”å›åˆå§‹ä½ç½®...")
        
        # å…ˆåœæ­¢è¿½è¸ª
        if self.state == SystemState.TRACKING:
            self._handle_start_stop()
        
        ret = self.robot.motion.joint_move(
            self.robot_cfg.home_joint_rad,
            RobotConstants.ABS,
            True,
            0.2
        )
        
        if ret[0] == 0:
            print("âœ… å·²è¿”å›åˆå§‹ä½ç½®")
        else:
            print(f"âŒ è¿”å›å¤±è´¥: {ret[0]}")
    
    def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        print("\nğŸ§¹ æ¸…ç†èµ„æº...")
        
        # åœæ­¢ä¼ºæœ
        if self.robot and self.control_cfg.use_servo_streaming:
            try:
                self.robot.motion.servo_move_enable(False)
                self.robot.motion.motion_abort()
            except Exception:
                pass
        
        # åœæ­¢è¿åŠ¨çº¿ç¨‹
        if self.motion_controller:
            self.motion_controller.stop_async_worker()
        
        # å…³é—­ç¡¬ä»¶
        # self.gripper.cleanup()
        self.camera.stop()
        
        if self.robot:
            self.robot.utils.safe_shutdown()
        
        # å…³é—­çª—å£
        try:
            cv2.destroyAllWindows()
        except Exception:
            pass
        
        print("âœ… æ¸…ç†å®Œæˆ")
    
    @staticmethod
    def _print_usage() -> None:
        """æ‰“å°ä½¿ç”¨è¯´æ˜"""
        print("\n" + "="*50)
        print("æ“ä½œæŒ‡å—")
        print("="*50)
        print("  [c] æ•è·å‚è€ƒå¸§")
        print("  [s] å¯åŠ¨/åœæ­¢è¿½è¸ª")
        print("  [p] æš‚åœ")
        print("  [i] è¿”å›åˆå§‹ä½ç½®")
        print("  [q] é€€å‡ºç¨‹åº")
        print("="*50 + "\n")


# ============================================================================
# ç¨‹åºå…¥å£
# ============================================================================

def main():
    """å¯¼å…¥æœºæ¢°è‡‚ä¾èµ–åº“"""
    __common.init_env()
    import jkrc
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºé…ç½®
    robot_config = RobotConfig()
    # gripper_config = GripperConfig()
    camera_config = CameraConfig()
    control_config = ControlConfig()
    vision_config = VisionConfig()
    
    # åˆ›å»ºç³»ç»Ÿ
    system = VisualServoSystem(
        robot_config,
        # gripper_config,
        camera_config,
        control_config,
        vision_config
    )
    
    # è¿è¡Œ
    system.run()


if __name__ == '__main__':
    main()